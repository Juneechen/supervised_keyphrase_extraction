# Keyphrase Extraction with Neural Networks

## Introduction

> What did you do and why is it interesting?

## Datasets

### Sci-HTC

### set 2

## The Models

> How do your model(s) work? (explain) Point out any important details regarding your approaches to unknown words, training, decoding, etc.

### bi-LSTM

**Input & Pre-process**  
From our dataset, we extracted 18000 random training samples, and we concatenate the 'title' and ‘abstract’ to be the input for the model. An input sample looks like this:

    Title:      Toward identifying inter-project clone sets for building useful libraries
    Abstract:   The present paper discusses how clone sets can be generated from an very large amount of source code. The knowledge of clone sets can help to manage software asset. For example, we can figure out the state of the asset easier, or we can build more useful libraries based on the knowledge.

Each input sample is first normalized by converting all to lower-case, and removing special characters.

    # keeping non-alphabetic char, space, and hyphen
    text = re.sub('[^\w\s-]', '', text)

It is then further pre-processed by tokenizing, removing English stopwords, and applying lemmatization. These process is done using `nltk.corpus.stopwords`, `nltk.tokenize.word_tokenize`, and `nltk.stem.WordNetLemmatizer`. The pre-processed input from the above example looks like this:

    ['toward', 'identifying', 'inter-project', 'clone', 'set', 'building', 'useful', 'library', 'present', 'paper', 'discus', 'clone', 'set', 'generated', 'large', 'amount', 'source', 'code', 'knowledge', 'clone', 'set', 'help', 'manage', 'software', 'asset', 'example', 'figure', 'state', 'asset', 'easier', 'build', 'useful', 'library', 'based', 'knowledge']

Padding and truncation are applied to these input tokens for the sequential model.
Before going into the model, each 'abstract' is tokenized and converted into contextual embeddings using the glove-wiki-gigaword-50 vectors. Padding and truncation are applied to embeddings for making all input sequences the same length.
To decide on the max length for setting the input, we mapped out the length (number of tokens) distribution over the pre-processed input from our traning samples. The max length is eventually set to 250 because about 98% of the train samples is within this length. We did experiment with other length settings as well to see how that affect our results, and a few experiments will be presented in later section.

[insert some distribution graph]

**Label**  
Labels are generated by marking the input sequences for keywords. Each label is a binary sequence of the same length as the input list of embedding vectors. `label[i]` is set to 1 if `input_sequences[i]` is part of the pre-defined keyphrases; otherwise `label[i] = 0`.

**unknown words**
Unkown words are represented by a vector of 0s with the length of embeddings dimension.

**output**

**inferrence**

**steps**

**how the model works internally**

### pre-trained BERT

## Experiments & Results

### bi-LSTM

Experiment 1:  
training sample=10000, embedding dim=50, maxLen=350, epoch=5, batchSize=32

    # 4m 17.5s
    Epoch 1/5
    2023-12-05 17:39:38.704371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.
    313/313 [==============================] - 60s 168ms/step - loss: 0.1556 - accuracy: 0.1800
    Epoch 2/5
    313/313 [==============================] - 46s 148ms/step - loss: 0.1257 - accuracy: 0.1904
    Epoch 3/5
    313/313 [==============================] - 45s 145ms/step - loss: 0.1256 - accuracy: 0.1928
    Epoch 4/5
    313/313 [==============================] - 51s 163ms/step - loss: 0.1256 - accuracy: 0.1773
    Epoch 5/5
    313/313 [==============================] - 53s 168ms/step - loss: 0.1256 - accuracy: 0.1775

Some predictions it gives by using a threshold of 0.3 when converting probablity distribution to binary prediction:

    actual: ['spectral learning', 'transfer learning']
    predicted: ['domain-transfer', 'learning', 'traditional', 'spectral', 'classification']
    actual: ['case study', 'verification and validation', 'very-large-scale software system']
    predicted: ['study', 'testing', 'commissioning', 'operation']
    actual: ['assistive technology', 'context aware mobile system', 'end-user programming', 'technology abandonment']
    predicted: ['user', 'programming', 'context', 'responsiveness']
    actual: ['collision avoidance', 'human-like character', 'motion planning', 'multiagent system', 'object grasping']
    predicted: ['conquer', 'freewill', 'framework', 'aim']
    actual: ['human-robot interaction', 'mood induction procedure']
    predicted: ['language', 'mood', 'induction', 'procedure']

### pre-trained BERT

### comparison with statistical model (TF-IDF)

## Summary

## Reference
